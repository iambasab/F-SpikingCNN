# -*- coding: utf-8 -*-
"""caltech.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19cew669s6xjPmBRbZaIxtG8aMJU4phX6
"""

! pip install nengo-dl 
! pip install nengo

import nengo
import nengo_dl

"""LOADING DATA"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/
!git clone https://github.com/shriya999/caltech_subset.git

import pandas as pd
import os
from matplotlib import image
import numpy as np
from skimage.color import rgb2gray
from skimage.transform import resize
from PIL import Image

path1 = "/content/caltech_subset/airplanes/"
path2 = "/content/caltech_subset/Motorbikes/"

dataset = []
labels = []
dimen1 = 15
dimen2 = 20

for filename in os.listdir(path1):
    data = rgb2gray(image.imread(path1+filename))
    data = resize(data, (dimen1, dimen2),anti_aliasing=True)
    dataset.append(data)
    labels.append([0,1])

for filename in os.listdir(path2):
    data = rgb2gray(image.imread(path2+filename))
    data = resize(data, (dimen1, dimen2),anti_aliasing=True)
    dataset.append(data)
    labels.append([1,0])

from sklearn.model_selection import train_test_split
import numpy as np
from matplotlib import pyplot as plt

X_train, X_test, y_train, y_test = train_test_split(dataset, labels, test_size=0.11, random_state=42, shuffle = True)

train_data = np.asarray(X_train, dtype=np.float32)
train_labels = np.asarray(y_train, dtype=np.float32)
test_data = np.asarray(X_test, dtype=np.float32)
test_labels = np.asarray(y_test, dtype=np.float32)

print(train_data.shape, test_data.shape, train_labels.shape, test_labels.shape)

"""CREATING DoG FILTERS"""

# Commented out IPython magic to ensure Python compatibility.
# import tensorflow as tf
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()

import numpy as np
#from tensorflow.examples.tutorials.mnist import input_data
from scipy.ndimage import correlate
# %matplotlib inline 
import matplotlib.pyplot as plt

#tf.compat.v1.reset_default_graph()
tf.reset_default_graph()

x_input = tf.placeholder(dtype=tf.float32, shape=[None, train_data.shape[1]*train_data.shape[2]], name='x_input')
y_input = tf.placeholder(dtype=tf.float32, shape=[None, train_labels.shape[1]], name='actual_label')

x_in = x_input
y_in = y_input

def dog_on(n,v,p):

  nr = np.floor(n/2) # half the size
  t = p * v # std deviation of surround (s2)
  
  x,y = np.mgrid[-nr:nr,-nr:nr]
  
  H  = 10*(1/(2 * np.pi * (v**2) )) * np.exp(-( (x**2) + (y**2) )/( 2 * (v**2) ))         # gaussian for center
  K  = 10*(1/(2 * np.pi * (t**2) )) * np.exp(-( (x**2) + (y**2) )/( 2 * (t**2) ))         # gaussian for surround
  
  s1 = np.sum( np.sum(H) )
  s2 = np.sum( np.sum(K) )
  
  D = ((s2 * H) - (s1 * K))
  return D

off_midget = -(dog_on(5,0.8,6.7))     # midget off center
on_midget = dog_on(11,1.04,6.7)    # midget on center
off_parasol = -(dog_on(61,8,4.8))     # parasol off center
on_parasol = dog_on(243,10.4,4.8)  # parasol on center


plt.figure()
plt.imshow( off_midget ,cmap="gray")
plt.axis('off')

plt.figure()
plt.imshow( on_midget ,cmap="gray")
plt.axis('off')

plt.figure()
plt.imshow( off_parasol ,cmap="gray")
plt.axis('off')

plt.figure()
plt.imshow( on_parasol ,cmap="gray")
plt.axis('off')


def DoG_conv(image):

  first_img = np.reshape( image, (28,28))
  on_conv = correlate(first_img, on_filt, mode='constant')
  off_conv = correlate( first_img, off_filt, mode='constant')

  final_img = np.zeros( (first_img.shape[0], first_img.shape[1]), dtype = np.float32 )
  for i in range(first_img.shape[0]):
    for j in range(first_img.shape[1]):
      final_img[i][j] = np.maximum( on_conv[i][j], off_conv[i][j] )
  
  return np.reshape(final_img,(784,))

"""FILTERING WITH ALL FOUR DoGS"""

sampling_size = 6
disp = 6
train_set = train_data[0:sampling_size,:,:]
test_set = test_data[0:sampling_size,:,:]

# midget cells

moff_train = []
print(train_set.shape)
modulus = train_set.shape[0]
for i in train_set:
  img = correlate(i, off_midget, mode='constant')
  moff_train.append( img )
  
mon_train = []
print(train_set.shape)
modulus = train_set.shape[0]
for i in train_set:
  img = correlate(i, on_midget, mode='constant')
  mon_train.append( img )

moff_test = []
print(test_set.shape)
for i in test_set:
  img = correlate(i, off_midget, mode='constant')
  moff_test.append( img )
  
mon_test = []
print(test_set.shape)
for i in test_set:
  img = correlate(i, on_midget, mode='constant')
  mon_test.append( img )

# parasol cells

poff_train = []
print(train_set.shape)
modulus = train_set.shape[0]
for i in train_set:
  img = correlate(i, off_parasol, mode='constant')
  poff_train.append( img )

poff_test = []
print(test_set.shape)
for i in test_set:
  img = correlate(i, off_parasol, mode='constant')
  poff_test.append( img )
  
# pon_train = []
# print(train_set.shape)
# modulus = train_set.shape[0]
# for i in train_set:
#   img = correlate(i, on_parasol, mode='constant')
#   pon_train.append( img )
  
# pon_test = []
# print(test_set.shape)
# for i in test_set:
#   img = correlate(i, on_parasol, mode='constant')
#   pon_test.append( img )

"""OUTPUTS WITH INDIVIDUAL FILTERS"""

for i in range(disp):
    plt.figure()
    plt.imshow( train_data[i],cmap="gray")
    plt.axis('off')
    plt.title(str(np.argmax(train_labels[i])));
    plt.show()
 
for i in range(disp):
    plt.figure()
    plt.imshow( moff_train[i],cmap="gray")
    plt.axis('off')
    plt.title(str(np.argmax(train_labels[i])));
    plt.show()
    
for i in range(disp):
    plt.figure()
    plt.imshow( mon_train[i],cmap="gray")
    plt.axis('off')
    plt.title(str(np.argmax(train_labels[i])));
    plt.show()
    
for i in range(disp):
    plt.figure()
    plt.imshow( poff_train[i],cmap="gray")
    plt.axis('off')
    plt.title(str(np.argmax(train_labels[i])));
    plt.show()
    
for i in range(disp):
    plt.figure()
    plt.imshow( pon_train[i],cmap="gray")
    plt.axis('off')
    plt.title(str(np.argmax(train_labels[i])));
    plt.show()

"""COMBINING OUTPUTS FROM DIFFERENT FILTERS"""

moff_mon_poff_pon = []
for k in range(len(pon_train)):
  img = np.zeros((dimen1,dimen2))
  for i in range(dimen1):
    for j in range(dimen2):
      max_val = max( max(pon_train[k][i][j], poff_train[k][i][j]), max(mon_train[k][i][j], moff_train[k][i][j]) )
      img[i][j] = max_val
  moff_mon_poff_pon.append(img)

moff_mon_poff = []
for k in range(len(pon_train)):
  img = np.zeros((dimen1,dimen2))
  for i in range(dimen1):
    for j in range(dimen2):
      max_val = max( poff_train[k][i][j], max(mon_train[k][i][j], moff_train[k][i][j]) )
      img[i][j] = max_val
  moff_mon_poff.append(img)

moff_poff = []
for k in range(len(pon_train)):
  img = np.zeros((dimen1,dimen2))
  for i in range(dimen1):
    for j in range(dimen2):
      max_val = max( poff_train[k][i][j], moff_train[k][i][j] )
      img[i][j] = max_val
  moff_poff.append(img)

moff_pon = []
for k in range(len(pon_train)):
  img = np.zeros((dimen1,dimen2))
  for i in range(dimen1):
    for j in range(dimen2):
      max_val = max( pon_train[k][i][j], moff_train[k][i][j] )
      img[i][j] = max_val
  moff_pon.append(img)

mon_poff = []
for k in range(len(pon_train)):
  img = np.zeros((dimen1,dimen2))
  for i in range(dimen1):
    for j in range(dimen2):
      max_val = max( poff_train[k][i][j], mon_train[k][i][j] )
      img[i][j] = max_val
  mon_poff.append(img)

mon_pon = []
for k in range(len(pon_train)):
  img = np.zeros((dimen1,dimen2))
  for i in range(dimen1):
    for j in range(dimen2):
      max_val = max( pon_train[k][i][j], mon_train[k][i][j] )
      img[i][j] = max_val
  mon_pon.append(img)

print(" with all four filters")

for i in range(disp):
    plt.figure()
    plt.imshow( moff_mon_poff_pon[i], cmap ="gray")
    plt.axis('off')
    plt.title(str(np.argmax(train_labels[i])));
    plt.show()

print(" with moff, mon and poff filters")

for i in range(disp):
    plt.figure()
    plt.imshow( moff_mon_poff[i], cmap ="gray")
    plt.axis('off')
    plt.title(str(np.argmax(train_labels[i])));
    plt.show()

print(" with moff and poff")

for i in range(disp):
    plt.figure()
    plt.imshow( moff_poff[i], cmap ="gray")
    plt.axis('off')
    plt.title(str(np.argmax(train_labels[i])));
    plt.show()

print(" with moff and pon")

for i in range(disp):
    plt.figure()
    plt.imshow( moff_pon[i], cmap ="gray")
    plt.axis('off')
    plt.title(str(np.argmax(train_labels[i])));
    plt.show()

print(" with mon and poff")

for i in range(disp):
    plt.figure()
    plt.imshow( mon_poff[i], cmap ="gray")
    plt.axis('off')
    plt.title(str(np.argmax(train_labels[i])));
    plt.show()

print(" with mon and pon")

for i in range(disp):
    plt.figure()
    plt.imshow( mon_pon[i], cmap ="gray")
    plt.axis('off')
    plt.title(str(np.argmax(train_labels[i])));
    plt.show()

"""RECONSTRUCTION"""

def kernel_picker(cell_type):
  kernel = 0
  stride = 0

  if(cell_type == 0):
    kernel = off_midget
    stride = 2
  elif(cell_type == 1):
    kernel = on_midget
    stride = 5
  else:
    kernel = off_parasol
    stride = 30
  
  return kernel,stride

import scipy.signal
import numpy as np

def recon_func(recon_img, kernel, coeff, x, y):
  ma = recon_img.shape[0]
  na = recon_img.shape[1]
  mb = kernel.shape[0]
  nb = kernel.shape[1]
  r1 = int(np.ceil(mb/2))
  s1 = int(np.ceil(nb/2))
  i1 = max(0, x-r1)

  for r in range(max(0,r1-x),mb):
    if(i1>=ma):
      break

    j1 = max(0,y-s1)
    for s in range(max(0,s1-y),nb):
      if(j1>=na):
        break
      recon_img[i1][j1] = recon_img[i1][j1] + kernel[r][s] * coeff
      j1 = j1+1
    i1 = i1+1
  return recon_img

def lat_inh(ma, na, i, sorted_keys, cfs, dict1, dict2):

  cfthr1 = np.zeros(len(sorted_keys)-i-1)
  count = 0
  temp = sorted_keys[i]
  (row1,col1) = dict1[temp]
  (kernel1,stride) = kernel_picker(dict2[temp])
  mb1 = kernel1.shape[0]
  nb1 = kernel1.shape[1]

  for ind in range(i,int(len(sorted_keys)) ):

    index = sorted_keys[ind - 1]

    (row2, col2) = dict1[index]
    (kernel2,stride2) = kernel_picker(dict2[index])
    mb2 = nb2 = kernel2.shape[0]

    psf = 0
    minrow1 = row1 - int((mb1 - 1)/2)
    maxrow1 = min(row1 + int((mb1 - 1)/2) , ma)
    mincol1 = col1 - int((nb1-1)/2)
    maxcol1 = min(col1 + int((nb1 - 1)/2), na)

    shiftrow1 = 0
    shiftcol1 = 0

    if(minrow1 < 0):
      shiftrow1 = 0 - minrow1
      minrow1 = 0
    else:
      shiftrow1 = 0

    if mincol1<0 :
      shiftcol1 = 0 - mincol1
      mincol1 = 0
    else:
      shiftcol1 = 0

    minrow2 = row2 - int((mb2 - 1)/2)
    maxrow2 = min(row2 + int((mb2 - 1)/2), ma)
    mincol2 = col2 - int((nb2 - 1)/2)
    maxcol2 = min(col2 + int((nb2-1)/2), na)

    if(minrow2<0):
      shiftrow2 = 0 - minrow2
      minrow2 = 0
    else:
      shiftrow2 = 0

    if(mincol2<0):
      shiftcol2 = 0 - mincol2
      mincol2 = 0
    else:
      shiftcol2 = 0

    rowloopstart = max (minrow1, minrow2)
    rowloopend = min (maxrow1, maxrow2)
    colloopstart = max (mincol1, mincol2)
    colloopend = min (maxcol1, maxcol2)    

    for r in range(rowloopstart, rowloopend+1):
      for c in range(colloopstart, colloopend+1):
          r1 = r - minrow1 + shiftrow1
          c1 = c - mincol1 + shiftcol1
          r2 = r - minrow2 + shiftrow2
          c2 = c - mincol2 + shiftcol2

          # print(r1,c1,r2,c2)
          # print(kernel.shape[0], kernel.shape[1], kernel2.shape[0], kernel2.shape[1])	 

          psf += kernel1[r1][c1] * kernel2[r2][c2]
    cfthr1[count - 1] = cfs[sorted_keys[ind - 1]] - (cfs[sorted_keys[i]] * psf)
    count = count+1
  return cfthr1

"""LATERAL INHIBITION"""

for k in range(int(disp)):

  plt.figure()
  plt.imshow( train_data[k], cmap ="gray")
  plt.axis('off')
  plt.show()
  
  lencfs = 0
  cfs = dict()
  dict1 = dict()        # storing the mapping from pixel values to location (i,j)
  dict2 = dict()         # storing the mapping from pixel values to type of filter 0:moff, 1:mon, 2:poff, 3:pon

  # spike_images = np.zeros( (4,moff_train[k].shape[0], moff_train[k].shape[1]) )
  # spike_images[0] = moff_train[k]
  # spike_images[1] = mon_train[k]
  # spike_images[2] = poff_train[k]
  # spike_images[3] = pon_train[k]
  # ordered_spikes = focal(spike_images)
  # print(ordered_spikes.size())

  for i in range(moff_train[k].shape[0]):
    for j in range(moff_train[k].shape[1]):
      cfs.update( {lencfs : moff_train[k][i][j]})
      dict1.update( {lencfs : (i,j)} )
      dict2.update( {lencfs : 0} )
      lencfs = lencfs + 1

  for i in range(mon_train[k].shape[0]):
    for j in range(mon_train[k].shape[1]):
      cfs.update( {lencfs : mon_train[k][i][j]})
      dict1.update( {lencfs : (i,j)} )
      dict2.update( {lencfs : 1} )
      lencfs = lencfs + 1

  for i in range(poff_train[k].shape[0]):
    for j in range(poff_train[k].shape[1]):
      cfs.update( {lencfs : poff_train[k][i][j]})
      dict1.update( {lencfs : (i,j)} )
      dict2.update( {lencfs : 2} )
      lencfs = lencfs + 1

  # for i in range(pon_train[k].shape[0]):
  #   for j in range(pon_train[k].shape[1]):
  #     dict1.update( {pon_train[k][i][j] : (i,j)} )
  #     dict2.update( {pon_train[k][i][j] : 3} )

  items = sorted(cfs.items(), key=lambda s: s[1], reverse=True)

  # new_dict = dict()
  # sorted_keys = []
  # for i in items:
  #   if i[1] == 0:
  #     continue
  #   else:
  #     new_dict.update( {i[0]:i[1]})
  #     sorted_keys.append(i[0])
  
  sorted_keys = list(cfs.keys())
  ro_image = np.zeros_like(moff_train[k]) # the rank ordered image
  print(len(sorted_keys))

  for i in range(int(len(sorted_keys)/3)):   # plotting the rank ordered image
    (x,y) = dict1[sorted_keys[i]]
    ro_image[x][y] = cfs[sorted_keys[i]]

  plt.figure()
  plt.imshow( ro_image, cmap ="gray")
  plt.axis('off')
  plt.show()

  for i in range(0,len(sorted_keys)-2):            # correcting the ro image with lateral inhibition
    cfthr1 = lat_inh( moff_train[k].shape[0], moff_train[k].shape[1], i, sorted_keys, cfs, dict1, dict2 )
    cfthr1 = sorted(cfthr1, reverse=True)
    for j in range(i+1,int(len(sorted_keys)) ):
      key = sorted_keys[j]
      cfs[key] = cfthr1[j-(i+1)]
 
  for i in range(int(len(sorted_keys)/3)):   # plotting the corrected rank ordered image
    (x,y) = dict1[sorted_keys[i]]
    ro_image[x][y] = cfs[sorted_keys[i]]

  plt.figure()
  plt.imshow( ro_image, cmap ="gray")
  plt.axis('off')
  plt.show()

  recon_image = np.zeros_like(moff_train[k]) # the reconstructed image
  index = 0
  for i in range(int(len(sorted_keys))):
    (x,y) = dict1[sorted_keys[i]]
    cell_type = dict2[sorted_keys[i]]
    (kernel,stride) = kernel_picker(cell_type)

    recon_image = recon_func(recon_image, kernel, cfs[sorted_keys[i]], x, y)

    if(index%9000 == 0):
      print("this is index number: ",index)
      plt.figure()
      plt.imshow( recon_image, cmap ="gray")
      plt.axis('off')
      plt.show()

    index+=1

for k in range(disp):

  plt.figure()
  plt.imshow( train_data[k], cmap ="gray")
  plt.axis('off')
  plt.show()

  dict1 = dict()        # storing the mapping from pixel values to location (i,j)
  dict2 = dict()         # storing the mapping from pixel values to type of filter 0:moff, 1:mon, 2:poff, 3:pon

  for i in range(moff_train[k].shape[0]):
    for j in range(moff_train[k].shape[1]):
      dict1.update( {moff_train[k][i][j] : (i,j)} )
      dict2.update( {moff_train[k][i][j] : 0} )

  for i in range(mon_train[k].shape[0]):
    for j in range(mon_train[k].shape[1]):
      dict1.update( {mon_train[k][i][j] : (i,j)} )
      dict2.update( {mon_train[k][i][j] : 1} )

  for i in range(poff_train[k].shape[0]):
    for j in range(poff_train[k].shape[1]):
      dict1.update( {poff_train[k][i][j] : (i,j)} )
      dict2.update( {poff_train[k][i][j] : 2} )

  # for i in range(pon_train[k].shape[0]):
  #   for j in range(pon_train[k].shape[1]):
  #     dict1.update( {pon_train[k][i][j] : (i,j)} )
  #     dict2.update( {pon_train[k][i][j] : 3} )

  sorted_keys = sorted(dict1.keys(), reverse=True)
  non_zero = np.nonzero(sorted_keys)
  temp = []
  for ind in non_zero[0]:
    temp.append(sorted_keys[ind])
  sorted_keys = temp

  ro_image = np.zeros_like(moff_train[k]) # the rank ordered image
  print(len(sorted_keys))
 
  for i in range(int(len(sorted_keys)/4)):
    (x,y) = dict1[sorted_keys[i]]
    ro_image[x][y] = sorted_keys[i]

  plt.figure()
  plt.imshow( ro_image, cmap ="gray")
  plt.axis('off')
  plt.show()

  recon_image = np.zeros_like(moff_train[k]) # the reconstructed image
  index = 0
  for i in range(int(len(sorted_keys))):

    (x,y) = dict1[sorted_keys[i]]
    cell_type = dict2[sorted_keys[i]]
    kernel = 0
    stride = 0

    if(cell_type == 0):
      kernel = off_midget
      stride = 2
    elif(cell_type == 1):
      kernel = on_midget
      stride = 5
    else:
      kernel = off_parasol
      stride = 30

    recon_image = recon_func(recon_image, kernel, sorted_keys[i], x, y)

    index+=1
    if(index%9000 == 0):
      print("this is index number: ",index)
      plt.figure()
      plt.imshow( recon_image, cmap ="gray")
      plt.axis('off')
      plt.show()


"""CHOOSING THE OPTIMAL COMBINATION"""

train_set = train_data
test_set = test_data

# choosing mon and poff

# midget cells

moff_train = []
print(train_set.shape)
modulus = train_set.shape[0]
for i in train_set:
  img = correlate(i, off_midget, mode='constant')
  moff_train.append( img )
  
mon_train = []
print(train_set.shape)
modulus = train_set.shape[0]
for i in train_set:
  img = correlate(i, on_midget, mode='constant')
  mon_train.append( img )

moff_test = []
print(test_set.shape)
for i in test_set:
  img = correlate(i, off_midget, mode='constant')
  moff_test.append( img )
  
mon_test = []
print(test_set.shape)
for i in test_set:
  img = correlate(i, on_midget, mode='constant')
  mon_test.append( img )

# # parasol cells

# poff_train = []
# print(train_set.shape)
# modulus = train_set.shape[0]
# for i in train_set:
#   img = correlate(i, off_parasol, mode='constant')
#   poff_train.append( img )

# poff_test = []
# print(test_set.shape)
# for i in test_set:
#   img = correlate(i, off_parasol, mode='constant')
#   poff_test.append( img )

final_train = []
final_test = []
disp = 6

recon = np.zeros((len(moff_train), dimen1,dimen2))   # say moff=0, mon=1,poff=2 and pon=3

final_train = moff_train
final_test = moff_test

train_features = np.asarray(final_train, dtype=np.float32)
train_labels = np.asarray(train_labels, dtype=np.float32)
test_features = np.asarray(final_test, dtype=np.float32)
test_labels = np.asarray(test_labels, dtype=np.float32)

hor = train_features.shape[1]*train_features.shape[2]
ver1 = train_features.shape[0]
ver2 = test_features.shape[0]
print(hor)
train_features = np.reshape(train_features, (ver1,hor))  
test_features = np.reshape(test_features, (ver2,hor))

"""LOADING THE DATA FOR NO FILTERS CASE"""

hor = train_data.shape[1]*train_data.shape[2]
ver1 = train_data.shape[0]
ver2 = test_data.shape[0]
print(hor)
train_features = np.reshape(train_data, (ver1,hor))  
test_features = np.reshape(test_data, (ver2,hor)) 
print(train_features.shape, test_data.shape)

"""THE NETWORK"""

import matplotlib.pyplot as plt

with nengo.Network() as net:
    net.config[nengo.Ensemble].max_rates = nengo.dists.Choice([100])
    neuron_type = nengo.LIF()

    # the input node that will be used to feed in input images
    inp = nengo.Node([0] * dimen1 * dimen2)      # else 28 * 56

    #out_1 = nengo.Probe(inp)

    # Conv1
    x = nengo_dl.tensor_layer( inp, tf.layers.conv2d, shape_in=(150, 200, 1), filters=8, kernel_size=3)
    
    #out_2 = nengo.Probe(x)
    x = nengo_dl.tensor_layer(x, neuron_type)

    # Pool1
    x = nengo_dl.tensor_layer(
        x, tf.layers.average_pooling2d, shape_in=(148, 198, 8),
        pool_size=2, strides=2)  

    # Conv2
    x = nengo_dl.tensor_layer(
        x, tf.layers.conv2d, shape_in=(74, 99,8),
        filters=16, kernel_size=5)
    
    #out_3 = nengo.Probe(x)    
    x = nengo_dl.tensor_layer(x, neuron_type)

    # Pool2
    x = nengo_dl.tensor_layer(x, tf.layers.average_pooling2d, shape_in=(70, 95, 16),pool_size=2, strides=2)
    
    #out_4 = nengo.Probe(x)

    # Conv3
    x = nengo_dl.tensor_layer(
        x, tf.layers.conv2d, shape_in=(35, 47, 16),filters=32, kernel_size=3)
    
    #out_5 = nengo.Probe(x)      
    x = nengo_dl.tensor_layer(x, neuron_type)

    # Pool3
    x = nengo_dl.tensor_layer(
        x, tf.layers.average_pooling2d, shape_in=(33, 45, 32),
        pool_size=2, strides=2)
    
    #out_6 = nengo.Probe(x)

    # add a dropout layer
    x = nengo_dl.tensor_layer(x, tf.layers.dropout, rate=0.4)

    x = nengo_dl.tensor_layer(x, tf.layers.dense, units=2)

    out_p = nengo.Probe(x)
    out_p_filt = nengo.Probe(x, synapse=0.1)

minibatch_size = 20
sim = nengo_dl.Simulator(net, minibatch_size = minibatch_size)

# add the single timestep to the training data
train_data = {inp: train_features[:, None, :], out_p: train_labels[:, None, :]}

n_steps = 60
test_data = {inp: np.tile(test_features[:minibatch_size*2, None, :], (1, n_steps, 1)), out_p_filt: np.tile(test_labels[:minibatch_size*2, None, :], (1, n_steps, 1))}

def objective(outputs, targets):
    return tf.nn.softmax_cross_entropy_with_logits_v2(logits=outputs, labels=targets)
  
opt = tf.train.AdamOptimizer(learning_rate=0.01)

def classification_accuracy(outputs,targets):
    print(outputs.shape, targets.shape)
    correct_prediction = tf.equal(tf.argmax(outputs[:, -1], axis=-1), tf.argmax(targets[:, -1], axis=-1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) * 100.0
    return accuracy

def classification_error(outputs, targets):
    return 100 * tf.reduce_mean(tf.cast(tf.not_equal(tf.argmax(outputs[:, -1], axis=-1), tf.argmax(targets[:, -1], axis=-1)), tf.float32))

print("accuracy before training: %.2f%%" % sim.loss(test_data, {out_p_filt: classification_accuracy}))

do_training = True
if do_training:
    sim.train(train_data, opt, objective={out_p: objective}, n_epochs=3)

print("accuracy after training: %.2f%%" % sim.loss(test_data, {out_p_filt: classification_accuracy}))

import matplotlib.pyplot as plt
sim.run_steps(n_steps, data={inp: test_data[inp][:minibatch_size]})

for i in range(5):
    plt.figure()
    plt.imshow( np.reshape(test_data[inp][i, 0], (dimen1, dimen2)), cmap = "gray")
    plt.axis('off')
    plt.show()

    plt.plot(sim.trange(), sim.data[out_p_filt][i])
    plt.legend([str(i+1) for i in range(2)], loc="upper left")
    plt.xlabel("time")
    plt.show()

sim.close()
